# Interpretation-semantic-textual-similarity
Ce projet est bas√© sur le cadre du concours SemEval de 2016. Pour deux phrases de texte, s1 et s2, le mod√®le calcule la similarit√© entre s1 et s2 et renvoie un score de similarit√©. Bien que ce score soit utile pour de nombreuses t√¢ches, il ne permet pas de savoir quelles parties des phrases sont √©quivalentes en termes de sens (ou tr√®s proches en termes de sens) et lesquelles ne le sont pas. Nous nous sommes donc concentr√©s sur ce probl√®me.  Nous travaillons √† partir d‚Äôun dataset de paires de phrases d√©j√† ‚Äòtokenis√©es‚Äô.  üìå Voici notre approche : - Identifier des morceaux de phrases (‚Äòchunks‚Äô) ayant chacun une unit√© de sens - Alignement de paires de chunks - Evaluation de la similarit√© entre 2 chunks  Type d'alignement : - EQUI : les deux chunks sont s√©mantiquement √©quivalents dans le contexte. - OPPO : les significations des chunks sont en opposition l'une avec l'autre dans le contexte. - SPE1 et SPE2 : les deux chunks ont des significations similaires, mais le chunk de la phrase 1 est plus sp√©cifique que le chunk de la phrase 2 ; et vice versa. - SIMI : significations similaires, mais pas de EQUI, OPPO, SPE1, ou SPE2. - REL : sens apparent√©, mais pas de SIMI, EQUI, OPPO, SPE1 ou SPE2. - NOALI : ce chunk n'a pas de chunk correspondant dans l'autre phrase.  Evaluation du score : Les scores pour NOALI seront ignor√©s. EQUI devrait avoir un score de 5. Les autres √©l√©ments doivent avoir un score sup√©rieur √† 0 mais inf√©rieur √† 5.  Apr√®s avoir mis en place quelques baselines pour la r√©alisation de cette t√¢che, nous focalisons sur l'impl√©mentation de mod√®les correspondant √† l'√©tat de l'art tels que les Transformers.
